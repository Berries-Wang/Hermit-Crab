09.Kubernetes网络模型之Pod与Service之间的网络交互

Kubernetes网络模型之Pod与Service之间的网络交互
=================================

### Pod-To-Service的网络

#### 01.为什么需要Service

*   图Pod-To-Service-1 ![](09.Kubernetes%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%B9%8BPod%E4%B8%8EService%E4%B9%8B%E9%97%B4%E7%9A%84%E7%BD%91%E7%BB%9C%E4%BA%A4%E4%BA%92.resources/0EAD0CC4-7E35-4D08-AA04-5C11C6F2C3DA.png)
*   Pod的IP并不是固定不变的，随着Pod的重新调度(水平伸缩，应用程序崩溃，节点重启等)，Pod的IP地址将会出现又消失。此时，Pod的客户端无法得知该访问哪一个IP地址.
*   一个Kubernets Service管理了一组Pod的状态，可以追踪一组Pod的IP地址的动态变化过程。一个Service拥有一个IP地址，并且充当了一组Pod的IP地址的**虚拟地址**。任何发送到Service的IP地址的数据包将被负载均衡到该Service对应的Pod上。在此情况下，Service关联的Pod可以随时间动态变化，客户端只需要知道Service的IP即可(该IP地址不会发生变化)
    *   注意，什么是虚拟地址(即虚拟IP)
    *   Kubernetes 自动为 Service 创建和维护了集群内部的分布式负载均衡，可以将发送到 Service IP 地址的数据包分发到 Service 对应的健康的 Pod 上
    *   但是，Service被重新创建之后，虚拟IP地址是否会变动呢?

#### 02\. Service负载均衡的实现

##### 02-1. 负载均衡实现策略1：netfilter and iptables

###### netfilter简介

*   Kubernetes 利用 Linux 内建的网络框架netfilter来实现负载均衡
*   Netfilter 是由 Linux 提供的一个框架，可以通过自定义 handler 的方式来实现多种网络相关的操作。Netfilter 提供了许多用于数据包过滤、网络地址转换、端口转换的功能，通过这些功能，自定义的 handler 可以在网络上转发数据包、禁止数据包发送到敏感的地址，等

###### iptables简介

*   iptables 是一个 user-space 应用程序，可以提供基于决策表的规则系统，以使用 netfilter 操作或转换数据包。在 Kubernetes 中，kube-proxy 控制器监听 apiserver 中的变化，并配置 iptables 规则。当 Service 或 Pod 发生变化时（例如 Service 被分配了 IP 地址，或者新的 Pod 被关联到 Service），kube-proxy 控制器将更新 iptables 规则，以便将发送到 Service 的数据包正确地路由到其后端 Pod 上。iptables 规则将监听所有发向 Service 的虚拟 IP 的数据包，并将这些数据包转发到该Service 对应的一个随机的可用 Pod 的 IP 地址，同时**iptables 规则将修改数据包的目标 IP 地址（从 Service 的 IP 地址修改为选中的 Pod 的 IP 地址)**。当 Pod 被创建或者被终止时，iptables 的规则也被对应的修改。换句话说，**iptables 承担了从 Service IP 地址到实际 Pod IP 地址的负载均衡的工作**。
*   在返回数据包的路径上，数据包从目标 Pod 发出，此时，**iptables 规则又将数据包的 IP 头从 Pod 的 IP 地址替换为 Service 的 IP** 地址。从请求的发起方来看，就好像始终只是在和 Service 的 IP 地址通信一样。

##### 02-2. 负载均衡实现策略2：IPVS(IP Virtual Server)

*   Kubernetes v1.11 开始，提供了另一个选择用来实现集群内部的负载均衡：IPVS。 IPVS（IP Virtual Server）也是基于 netfilter 构建的，在 Linux 内核中实现了传输层的负载均衡。IPVS 被合并到 LVS（Linux Virtual Server）当中，充当一组服务器的负载均衡器。IPVS 可以转发 TCP / UDP 请求到实际的服务器上，使得一组实际的服务器看起来像是只通过一个单一 IP 地址访问的服务一样。IPVS 的这个特点天然适合与用在 Kubernetes Service 的这个场景下。
*   当声明一个 Kubernetes Service 时，你可以指定是使用 iptables 还是 IPVS 来提供集群内的负载均衡工鞥呢。IPVS 是转为负载均衡设计的，并且使用更加有效率的数据结构（hash tables），相较于 iptables，可以支持更大数量的网络规模。当创建使用 IPVS 形式的 Service 时，Kubernetes 执行了如下三个操作：
    1.  在节点上创建一个 dummy IPVS interface
    2.  将 Service 的 IP 地址绑定到该 dummy IPVS interface
    3.  为每一个 Service IP 地址创建 IPVS 服务器
*   将来，IPVS 有可能成为 kubernetes 中默认的集群内负载均衡方式。这个改变将只影响到集群内的负载均衡，后续讨论将以 iptables 为例子，所有讨论对 IPVS 是同样适用的
*   这样理解：
    1.  **【暂时，不确定对】如图Pod-To-Service-1，可以将Service看作是一个Pod里面的一个容器里面的一个应用A(特殊的应用)，Service的IP(即虚拟地址，也叫ClusterIP)就是这个Pod的IP地址，当使用ClusterIP:Port来访问Service的时候，就是访问这个应用A，然后应用A进行负载均衡，将请求重定向到对应的Pod.**

#### 03\. Pod-To-Service数据包的传递

*   ![](09.Kubernetes%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%B9%8BPod%E4%B8%8EService%E4%B9%8B%E9%97%B4%E7%9A%84%E7%BD%91%E7%BB%9C%E4%BA%A4%E4%BA%92.resources/pod-to-service.6718b584.gif)
*   流程分析
    1.  数据包首先通过Pod的etho网卡发出
    2.  数据经过虚拟网卡veth0到达网桥cbr0.
    3.  网桥上的APR协议查找不到该Service，所以数据包被发送到root namespace中的默认路由 eth0
        *   此时，在数据包被etho接受之前，数据包将通过iptables过滤，iptables使用其规则(由kube-proxy根据Service、Pod的变化在节点上创建的iptables规则)重写数据包的目标地址(从Service的IP地址修改为一个具体的Pod的IP地址)
    4.  数据包现在的目标地址时Pod4，而不是Service的虚拟IP地址。iptables使用Linux内核的conntrack工具包来记录具体选择了哪一个Pod，以便可以将未来的数据包路由到同一个Pod。简而言之，iptables直接在节点上完成了集群内负载均衡的功能。数据包后续如何发送到Pod上，其路由方式就是Pod-to-Pod的网络模式了.

#### 04\. Service-to-Pod数据包的传递

*   ![](09.Kubernetes%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%B9%8BPod%E4%B8%8EService%E4%B9%8B%E9%97%B4%E7%9A%84%E7%BD%91%E7%BB%9C%E4%BA%A4%E4%BA%92.resources/service-to-pod.4393f600.gif)
*   流程分析
    1.  接受到该请求的Pod将会发送返回数据包，其中标记源IP为接受请求Pod的自己的IP，目标IP为最初发送对应请求的Pod的IP
    2.  当数据包进入节点后，数据包经过iptables的过滤，此时记录在conntrack中的信息将被用来修改数据包的源地址(**从接收请求的Pod的IP地址修改为Service的IP地址**)
    3.  数据包将经过网桥、以及虚拟网卡veth0
    4.  最终到达Pod的网卡eth0